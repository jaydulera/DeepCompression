{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled17.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AH0o3a_Y9OCv"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from keras.datasets import cifar10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMQU6E879bm-",
        "outputId": "00c1132e-b42b-4c4b-807f-9283e20a31d8"
      },
      "source": [
        "(X_train , y_train) , (X_test , y_test) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB6vL8Q49gOh"
      },
      "source": [
        "X_train = X_train.astype(float) / 255.0\r\n",
        "X_test = X_test.astype(float) / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dqs2Q9qd9vzA"
      },
      "source": [
        "from keras import Sequential\r\n",
        "from keras.layers import Conv2D\r\n",
        "from keras.layers import MaxPool2D\r\n",
        "from keras.layers import Flatten\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Dropout\r\n",
        "from keras.layers import BatchNormalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1w8m16I90iE"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Conv2D(16 , (3 , 3), activation='relu',input_shape = (32 , 32 , 3), kernel_initializer='he_uniform', padding='same' , kernel_regularizer='l2'))\r\n",
        "model.add(Conv2D(16 , (3 , 3), activation='relu', kernel_initializer='he_uniform', padding='same' , kernel_regularizer='l2'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(MaxPool2D(2 , 2))\r\n",
        "model.add(Dropout(0.1))\r\n",
        "model.add(Conv2D(32 , (5 , 5), activation='relu', kernel_initializer='he_uniform', padding='same' , kernel_regularizer='l2'))\r\n",
        "model.add(Conv2D(32 , (5 , 5), activation='relu', kernel_initializer='he_uniform', padding='same' , kernel_regularizer='l2'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(MaxPool2D(2 , 2))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(32 , activation='relu', kernel_initializer='he_uniform', kernel_regularizer='l2'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(Dropout(0.3))\r\n",
        "model.add(Dense(10 , activation='softmax'))\r\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy ', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "149Q0jfY_LqI"
      },
      "source": [
        "y_train1 = keras.utils.to_categorical(y_train)\r\n",
        "y_test1 = keras.utils.to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDjbsFw2_WqR",
        "outputId": "0dc42037-d2c2-42a8-cd51-0556e09e8410"
      },
      "source": [
        "history = model.fit(X_train , y_train1 , epochs = 3 , batch_size = 32 , validation_split=0.2 , use_multiprocessing=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1250/1250 [==============================] - 175s 140ms/step - loss: 2.7937 - accuracy: 0.4433 - val_loss: 1.8705 - val_accuracy: 0.5500\n",
            "Epoch 2/3\n",
            "1250/1250 [==============================] - 177s 141ms/step - loss: 1.7055 - accuracy: 0.5833 - val_loss: 1.6372 - val_accuracy: 0.5688\n",
            "Epoch 3/3\n",
            "1250/1250 [==============================] - 171s 137ms/step - loss: 1.5367 - accuracy: 0.6203 - val_loss: 1.6964 - val_accuracy: 0.5746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prf-Ke72_hBy",
        "outputId": "a05749c1-29f5-4c27-8b35-c27f0502b0da"
      },
      "source": [
        "y_train1[:1000].size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM1nZxNf_iTs",
        "outputId": "f96503af-90d6-4e14-bd55-1326a0f52563"
      },
      "source": [
        "model.evaluate(X_test , y_test1 , verbose = 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5697920322418213, 0.5485000014305115]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SCEaYgqCWHq",
        "outputId": "ada3a985-2203-4f34-85cc-7bf062f1e56b"
      },
      "source": [
        "model.evaluate(X_test , y_test1 , verbose = 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.3026092052459717, 0.10000000149011612]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyK70RYZDZZx",
        "outputId": "4450f388-a9b5-432e-c06b-4ecb68f3cccb"
      },
      "source": [
        "model.evaluate(X_test , y_test1 , verbose = 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7099330425262451, 0.5715000033378601]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufPz0qzsGVxg"
      },
      "source": [
        "import tempfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQbJsloBDJKz",
        "outputId": "f3c1b3ce-d69a-4bfb-b606-d5ca5e01cd82"
      },
      "source": [
        "_, keras_file = tempfile.mkstemp('.h5')\r\n",
        "print('Saving model to: ', keras_file)\r\n",
        "tf.keras.models.save_model(model, keras_file, include_optimizer=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to:  /tmp/tmp4q_ldahj.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw1CqgIqDYgs"
      },
      "source": [
        "def get_gzipped_model_size(file):\r\n",
        "  # It returns the size of the gzipped model in bytes.\r\n",
        "  import os\r\n",
        "  import zipfile\r\n",
        "\r\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\r\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\r\n",
        "    f.write(file)\r\n",
        "\r\n",
        "  return os.path.getsize(zipped_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnbJVGA6DN89",
        "outputId": "d225d818-dae1-4af1-fa02-52d60ae713d2"
      },
      "source": [
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of gzipped baseline Keras model: 398103.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puuo8VAvDlm9",
        "outputId": "c750a1dd-132a-4e8f-b51a-a820660ba011"
      },
      "source": [
        "pip install tensorflow_model_optimization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_model_optimization\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
            "\r\u001b[K     |██                              | 10kB 13.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20kB 17.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 30kB 13.2MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 40kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 51kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 61kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 71kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 81kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 92kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 102kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 112kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 122kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 133kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 143kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 153kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 163kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow_model_optimization) (1.15.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_model_optimization) (0.1.5)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorflow_model_optimization) (1.19.4)\n",
            "Installing collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpA6H-zIDUt6"
      },
      "source": [
        "import tensorflow_model_optimization as tfmot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PG5W0XhDjBE"
      },
      "source": [
        "cluster_weights = tfmot.clustering.keras.cluster_weights\r\n",
        "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\r\n",
        "clustering_params = {\r\n",
        "  'number_of_clusters': 32,\r\n",
        "  'cluster_centroids_init': CentroidInitialization.LINEAR\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccqI2GD9EE1T"
      },
      "source": [
        "clustered_model = cluster_weights(model, **clustering_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_F5l8lyEG0Q",
        "outputId": "91107800-9f62-4f12-f8f3-1bb75b0ff6da"
      },
      "source": [
        "_, keras_file1 = tempfile.mkstemp('.h5')\r\n",
        "print('Saving model to: ', keras_file1)\r\n",
        "tf.keras.models.save_model(clustered_model, keras_file1, include_optimizer=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to:  /tmp/tmpjatd4f0y.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0WqVJ6lEh1Y",
        "outputId": "b92bbef3-52c0-4063-db74-77727e0bf84c"
      },
      "source": [
        "print(\"Size of gzipped model after wieght clustering: %.2f bytes\" % (get_gzipped_model_size(keras_file1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of gzipped model after wieght clustering: 102984.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou5myaetEplE"
      },
      "source": [
        "batch_size = 64\r\n",
        "epochs = 2\r\n",
        "validation_split = 0.175\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPgg3yKiEyKU"
      },
      "source": [
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\r\n",
        "num_images = 32 * (1 - validation_split)\r\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BwMi_RJE1Jj"
      },
      "source": [
        "pruning_params = {\r\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.1,\r\n",
        "                                                               final_sparsity=0.50,\r\n",
        "                                                               begin_step=0,\r\n",
        "                                                               end_step=end_step)\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0vqsZB_E3od",
        "outputId": "953b9f2e-06a2-415c-a65c-ce0d2c91732f"
      },
      "source": [
        "model_for_pruning = prune_low_magnitude(model, **pruning_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZSRrdq3FCgb",
        "outputId": "6dd9d952-df9e-4b69-c58a-f03d8b85cc8a"
      },
      "source": [
        "_, keras_file2 = tempfile.mkstemp('.h5')\r\n",
        "print('Saving model to: ', keras_file2)\r\n",
        "tf.keras.models.save_model(model_for_pruning, keras_file2, include_optimizer=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to:  /tmp/tmp_1izwzqz.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fmfmo_JJGcV1",
        "outputId": "ff76b88e-7075-4250-dd1d-00aed3fd4496"
      },
      "source": [
        "print(\"Size of gzipped model after pruning: %.2f bytes\" % (get_gzipped_model_size(keras_file2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of gzipped model after pruning: 401977.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "JYcxzK-hGgoc",
        "outputId": "d1e23e4a-84f4-4433-e375-93422b659c41"
      },
      "source": [
        "clustered_model = cluster_weights(model_for_pruning, **clustering_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-be405ac88460>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclustered_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_for_pruning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mclustering_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/clustering/keras/cluster.py\u001b[0m in \u001b[0;36mcluster_weights\u001b[0;34m(to_cluster, number_of_clusters, cluster_centroids_init, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     return keras.models.clone_model(to_cluster,\n\u001b[1;32m    148\u001b[0m                                     \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                                     clone_function=_add_clustering_wrapper)\n\u001b[0m\u001b[1;32m    150\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_cluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_add_clustering_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_cluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    426\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     return _clone_sequential_model(\n\u001b[0;32m--> 428\u001b[0;31m         model, input_tensors=input_tensors, layer_fn=clone_function)\n\u001b[0m\u001b[1;32m    429\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     return _clone_functional_model(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36m_clone_sequential_model\u001b[0;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[1;32m    329\u001b[0m     cloned_layer = (\n\u001b[1;32m    330\u001b[0m         \u001b[0m_clone_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         if isinstance(layer, InputLayer) else layer_fn(layer))\n\u001b[0m\u001b[1;32m    332\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloned_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0mlayer_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloned_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/clustering/keras/cluster.py\u001b[0m in \u001b[0;36m_add_clustering_wrapper\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m    135\u001b[0m                                           \u001b[0mnumber_of_clusters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                                           \u001b[0mcluster_centroids_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                                           **kwargs)\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_wrap_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/clustering/keras/cluster_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layer, number_of_clusters, cluster_centroids_init, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m           \u001b[0;34m'either be a `ClusterableLayer` instance, or should be supported by '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m           'the ClusteringRegistry. You passed: {input}'.format(\n\u001b[0;32m---> 81\u001b[0;31m               \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m           )\n\u001b[1;32m     83\u001b[0m       )\n",
            "\u001b[0;31mValueError\u001b[0m: Please initialize `Cluster` with a supported layer. Layers should either be a `ClusterableLayer` instance, or should be supported by the ClusteringRegistry. You passed: <class 'tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HENCudHmHBrV",
        "outputId": "a028d515-f3c6-4564-e523-7c0d62027140"
      },
      "source": [
        "model = Sequential([\r\n",
        "cluster_weights(Conv2D(16 , (3 , 3), activation='relu',input_shape = (32 , 32 , 3), kernel_initializer='he_uniform', padding='same' , kernel_regularizer='l2') , **clustering_params),\r\n",
        "cluster_weights(Conv2D(16 , (3 , 3), activation='relu',input_shape = (32 , 32 , 3), kernel_initializer='he_uniform', padding='same' , kernel_regularizer='l2') , **clustering_params),\r\n",
        "BatchNormalization(),\r\n",
        "MaxPool2D(2 , 2),\r\n",
        "Dropout(0.1),\r\n",
        "cluster_weights(Conv2D(32 , (5 , 5), activation='relu', kernel_initializer='he_uniform', padding='same' , kernel_regularizer='l2' ), **clustering_params),\r\n",
        "cluster_weights(Conv2D(32 , (5 , 5), activation='relu', kernel_initializer='he_uniform', padding='same' , kernel_regularizer='l2' ), **clustering_params),\r\n",
        "BatchNormalization(),\r\n",
        "MaxPool2D(2 , 2),\r\n",
        "Dropout(0.2),\r\n",
        "Flatten(),\r\n",
        "prune_low_magnitude(Dense(32 , activation='relu', kernel_initializer='he_uniform', kernel_regularizer='l2' ) , **pruning_params),\r\n",
        "BatchNormalization(),\r\n",
        "Dropout(0.3),\r\n",
        "Dense(10 , activation='softmax')\r\n",
        "])\r\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy ', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ0Ch9QnPDdI",
        "outputId": "313f2ddf-e002-48bb-c50c-a60d4d194a8b"
      },
      "source": [
        "_, keras_file4 = tempfile.mkstemp('.h5')\r\n",
        "print('Saving model to: ', keras_file4)\r\n",
        "tf.keras.models.save_model(model, keras_file4, include_optimizer=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to:  /tmp/tmp7z1k2hjo.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k43TtFrgT4It",
        "outputId": "d173dcfd-b33d-441b-a364-3a4eee3fe84c"
      },
      "source": [
        "print(\"Size of gzipped model after pruning: %.2f bytes\" % (get_gzipped_model_size(keras_file4)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of gzipped model after pruning: 103593.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWkuHcwhT8i_",
        "outputId": "9caf3c74-2ff2-46b4-cfa3-57150a448976"
      },
      "source": [
        "_, keras_file4 = tempfile.mkstemp('.h5')\r\n",
        "print('Saving model to: ', keras_file4)\r\n",
        "tf.keras.models.save_model(model, keras_file4, include_optimizer=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to:  /tmp/tmp8tnlvyi6.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O7X14fjUBVY",
        "outputId": "5587ff87-aeaa-411f-d6fa-e4493e8d8dcf"
      },
      "source": [
        "print(\"Size of gzipped model after pruning: %.2f bytes\" % (get_gzipped_model_size(keras_file4)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of gzipped model after pruning: 288877.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QpXw3VZUpS7"
      },
      "source": [
        "quantize_model = tfmot.quantization.keras.quantize_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH0cTLXcU1yQ",
        "outputId": "fe8c11cf-10bb-4ce1-ac48-cb1b8549067f"
      },
      "source": [
        "tfmot.quantization.keras.quantize_scope(\r\n",
        "    *pruning_params,\r\n",
        "    *clustering_params\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.utils.generic_utils.CustomObjectScope at 0x7f0d8fac2908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "zbjFHEmoVcG5",
        "outputId": "a4b3a9ae-b8e5-4b6f-ae6e-051e835ebe65"
      },
      "source": [
        "q_aware_model = quantize_model(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py\u001b[0m in \u001b[0;36mquantize_apply\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    382\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m     \u001b[0mmodel_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_clone_model_with_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py\u001b[0m in \u001b[0;36m_clone_model_with_weights\u001b[0;34m(model_to_clone)\u001b[0m\n\u001b[1;32m    331\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_clone_model_with_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_clone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m     \u001b[0mcloned_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_clone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m     \u001b[0mcloned_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_clone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    427\u001b[0m     return _clone_sequential_model(\n\u001b[0;32m--> 428\u001b[0;31m         model, input_tensors=input_tensors, layer_fn=clone_function)\n\u001b[0m\u001b[1;32m    429\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36m_clone_sequential_model\u001b[0;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0m_clone_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         if isinstance(layer, InputLayer) else layer_fn(layer))\n\u001b[0m\u001b[1;32m    332\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloned_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36m_clone_layer\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_clone_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize_annotate.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'layer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m       printable_module_name='layer')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    346\u001b[0m     (cls, cls_config) = class_and_config_for_serialized_keras_object(\n\u001b[0;32m--> 347\u001b[0;31m         config, module_objects, custom_objects, printable_module_name)\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[0;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprintable_module_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown layer: ClusterWeights",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-ca015630f54d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mq_aware_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py\u001b[0m in \u001b[0;36mquantize_model\u001b[0;34m(to_quantize)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mannotated_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantize_annotate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_quantize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mquantize_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotated_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py\u001b[0m in \u001b[0;36mquantize_apply\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    384\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     raise ValueError(\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0;34m'Unable to clone model. This generally happens if you used custom Keras layers or objects '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0;34m'in your model. Please specify them via `quantize_scope` for your calls to `quantize_model` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;34m'and `quantize_apply`.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unable to clone model. This generally happens if you used custom Keras layers or objects in your model. Please specify them via `quantize_scope` for your calls to `quantize_model` and `quantize_apply`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqJhPdSfVlHd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}